{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06e2380b-5d55-402e-b923-b2bfd479dfde",
   "metadata": {},
   "source": [
    "## Script for creating the traning x, y set for training A Neural network recognizing categories of different clothing items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9e028f-e255-404a-9429-fda721edbad4",
   "metadata": {},
   "source": [
    "### Source of the separated dataset: https://www.kaggle.com/datasets/agrigorev/clothing-dataset-full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "491d139a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86617282-b453-4b75-81b0-e4be2ec10ad8",
   "metadata": {},
   "source": [
    "#### Reading the image labels set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14a7cc77-0de9-4010-b11b-fd8cecfb429f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"images.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92a134a4-fd5e-4268-a2dc-bb94effbdcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = \"images_original\"\n",
    "files = os.listdir(images_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88d87974-c63c-401f-b5d9-bc69e0994fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_list = np.empty((len(files),), dtype='<U40')\n",
    "for i in range(files_list.size):\n",
    "    files_list[i] = files[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d65b453-0736-44f8-8960-79b6e414333b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['d7ed1d64-2c65-427f-9ae4-eb4aaa3e2389.jpg',\n",
       "       '5c1b7a77-1fa3-4af8-9722-cd38e45d89da.jpg',\n",
       "       'b2e084c7-e3a0-4182-8671-b908544a7cf2.jpg', ...,\n",
       "       'd4b0b957-5632-4df1-aba6-e562e2a84687.jpg',\n",
       "       '89074ff2-ebfe-4790-892e-8513625a05b0.jpg',\n",
       "       '0949e8e0-c807-4b6d-8453-80a05f1b733e.jpg'], dtype='<U40')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9df8277a-fc20-432d-8112-acc20833a671",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.empty((files_list.size,), dtype=np.ndarray)\n",
    "y_train = np.empty((files_list.size), dtype='<U40')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35add4b8-9409-4e97-8cad-76679f127fde",
   "metadata": {},
   "source": [
    "#### Creating the x, y training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5966691-dd62-4a5b-b3d4-710f849224af",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "for element in files_list:\n",
    "    splitted = element.split(\".\")\n",
    "    if not df.empty and splitted[0] in df[\"image\"].values:\n",
    "        #print(f\"{round(index/files_list.size * 100,2)}%\\n\")\n",
    "        result = df.loc[df[\"image\"] == splitted[0]].iloc[0][\"label\"]\n",
    "        img = Image.open(f\"{images_path}/{element}\")\n",
    "        img = img.resize((32, 32))\n",
    "        img = img.convert('L')\n",
    "        img_array = np.array(img)\n",
    "        flattened_img = img_array.flatten()\n",
    "        x_train[index] = flattened_img\n",
    "        y_train[index] = result\n",
    "        index += 1\n",
    "    else:\n",
    "        print(f\"No label found for image: {element}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e18999-003a-4650-939b-5609df553660",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9a00eb-d8ee-458b-a87b-ada9c556f24b",
   "metadata": {},
   "source": [
    "#### x_train size before getting rid of the None values(None values mean that no connection found between the a label and related image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa315273-1990-4855-a69a-40e028a56b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0b4d58-f780-4cb9-bc73-5d6a3f877f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = [i for i in x_train if i is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b128959-e333-4489-8425-a763d171fb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.empty((len(index),), dtype=np.ndarray)\n",
    "for i in range(x_train.size):\n",
    "    x_train[i] = index[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aeb01fe-1a25-444e-8919-204db0d56f6a",
   "metadata": {},
   "source": [
    "#### Cleaned x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043412a9-51d7-4bd8-9273-f56c373e4de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85edda4c-268b-443e-bdf0-e9349abee198",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f58ff24-34b5-47ba-90d5-ff48d45c8e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = [i for i in y_train if i != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca9dc3b-b3fb-49b9-afd2-f3f77bc8f6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97548afd-08b3-4d37-b945-ac8d6bd49e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.empty((len(index),), dtype=np.ndarray)\n",
    "for i in range(y_train.size):\n",
    "    y_train[i] = index[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca46bd0-ad90-446b-ba57-ff82e9afb33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ef887f-c0a6-46e8-8374-94843645d8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"label\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add681c8-d3f6-40ec-b015-42218b613bc7",
   "metadata": {},
   "source": [
    "#### Saving the x, and y training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2b6102-e391-4842-8558-ba846c6dbcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('x_train_save.npy', x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23c7890-734d-4d10-b181-18496ec707dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('y_train_save.npy', y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
